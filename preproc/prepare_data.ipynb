{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a214425f-fdfa-4902-8a90-140a8ea2619b",
   "metadata": {},
   "source": [
    "# This is the Preprocessing codes to analyze the running invervention dataset\n",
    "\n",
    "## Gitrepo\n",
    "    https://github.com/Vincent-wq/interventionMDD\n",
    "    \n",
    "## Dataset:\n",
    "    0. Data source: [https://openneuro.org/datasets/ds003799/versions/1.0.0]( Openneuro)\n",
    "    1. Imaging data MRI *3 sessions;\n",
    "    2. Depression measures: Description: German version of the Center for Epidemiological Studies Depression Scale(CES-D). Hautzinger, M., Bailer, M., Hofmeister, D., & Keller, F. (2012). Allgemeine Depressionsskala (ADS). Manual (2. Auflage). Göttingen: Hogrefe Verlag GmbH. This self-assessing scale comprises 20 items covering depressive symptoms in the emotional, motivational, cognitive, somatic, and motoric domain. Participants had to indicate the extent to which the given conditions apply to them in the last week on a four-point scale ranging from “infrequent” to “the most time”.\n",
    "\n",
    "## Preprocessing steps:\n",
    "    1. Pre-registration: https://osf.io/yg5bu/\n",
    "    2. Preprocessing steps: \n",
    "        2.1 fMRIPrep 20.2.7\n",
    "        2.2 QA\n",
    "        2.3 TBD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4f0d0f-c916-47b9-8b36-b2df839db790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libs and envs\n",
    "import sys\n",
    "proj_path_str='/scratch/interventionMDD'\n",
    "sys.path.append(proj_path_str)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# main PATH\n",
    "main_dir = Path(proj_path_str)\n",
    "data_dir = main_dir / 'data' \n",
    "fig_dir =  main_dir / 'figs' \n",
    "\n",
    "# Tabular data files \n",
    "participant_file = data_dir / 'participants.tsv'  # Inormation from download database.\n",
    "mdd_score_file   = data_dir / 'phenotype_CES-D.tsv'  # Inormation from download database.\n",
    "\n",
    "# brain measure data save file \n",
    "des_sv_file = data_dir / 'fs_measures_Des.csv'     # Brain measures in Des atlas.\n",
    "dkt_sv_file = data_dir / 'fs_measures_DKT.csv'     # Brain measures in DKT atlas.\n",
    "des_hippo_sv_file = data_dir / 'fs_hippo_Des.csv'  # Hippocampus measures in Des atlas.\n",
    "dkt_hippo_sv_file = data_dir / 'fs_hippo_DKT.csv'  # Hippocampus measures in DKT atlas. \n",
    "\n",
    "# read subject demnographics \n",
    "sub_data = pd.read_csv(participant_file, sep='\\t')\n",
    "sub_data.index=sub_data['participant_id']\n",
    "sub_data=sub_data.drop(columns=['participant_id']).copy()\n",
    "sub_col_list = ['participant_id', 'group', 'age', 'sex', 'size', 'weight'];\n",
    "\n",
    "# read CES-D score\n",
    "mdd_data  = pd.read_csv(mdd_score_file, sep='\\t')\n",
    "mdd_data.index = mdd_data['participant_id']\n",
    "mdd_data=mdd_data.drop(columns=['participant_id']).copy()\n",
    "moca_list = ['participant_id', 'CES-D_1', 'CES-D_2', 'CES-D_3'];\n",
    "\n",
    "##join data\n",
    "data_df = sub_data.join(mdd_data, on = ['participant_id'], how='left').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3340a5d",
   "metadata": {},
   "source": [
    "# Getting freesurfer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d73523-be13-422a-90c4-ed9d936ee3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading session  1  freesurfer stats data...\n",
      "Reading session  2  freesurfer stats data...\n",
      "Reading session  3  freesurfer stats data...\n",
      "1 48\n",
      "2 48\n",
      "3 48\n"
     ]
    }
   ],
   "source": [
    "# Freesurfer brain measures\n",
    "save_file = 1\n",
    "sub_list = data_df.iloc[:, []].copy()\n",
    "\n",
    "ses_list = ['1', '2', '3']\n",
    "fs_ses_file_list = [ ( main_dir / \"data\" / \"fs_measures\" / ('ses-'+x) ) for x in ses_list]\n",
    "n_ses = len(ses_list)\n",
    "\n",
    "files_2_read={'seg'      : ['aseg_stats.txt', 'wmparc_stats.txt'],\n",
    "              'Destrieux': {'ct': '.a2009s.thickness.txt',  'area':'.a2009s.area.txt',   'volume':'.a2009s.volume.txt'},\n",
    "              'DKT'      : {'ct': '.DKTatlas.thickness.txt','area':'.DKTatlas.area.txt', 'volume':'.DKTatlas.volume.txt'}}\n",
    "              \n",
    "group_data={}\n",
    "for i_ses in range(n_ses):\n",
    "    \"\"\"\n",
    "    Loop to gather all the freesurfer outputs for all the sesions.\n",
    "    Output: all_data (dataframe).\n",
    "    \"\"\"\n",
    "    print('Reading session ' , str(ses_list[i_ses]), ' freesurfer stats data...')\n",
    "    raw_data_path = fs_ses_file_list[i_ses]\n",
    "    \n",
    "    # preparing files\n",
    "    subcortical_file = raw_data_path / (files_2_read['seg'][0]); wm_file = raw_data_path / (files_2_read['seg'][1]);\n",
    "    # Des parcellation\n",
    "    lh_Des_ct_file = raw_data_path / ('lh'+files_2_read['Destrieux']['ct']);  rh_Des_ct_file = raw_data_path /  ('rh'+files_2_read['Destrieux']['ct']);\n",
    "    lh_Des_vol_file = raw_data_path / ('lh'+files_2_read['Destrieux']['volume']); rh_Des_vol_file = raw_data_path / ('rh'+files_2_read['Destrieux']['volume']);\n",
    "    lh_Des_area_file = raw_data_path / ('lh'+files_2_read['Destrieux']['area']); rh_Des_area_file = raw_data_path / ('rh'+files_2_read['Destrieux']['area']);\n",
    "    # DKT parcellation\n",
    "    lh_DKT_area_file = raw_data_path / ('lh'+files_2_read['DKT']['area']);       rh_DKT_area_file = raw_data_path / ('rh'+files_2_read['DKT']['area']);\n",
    "    lh_DKT_ct_file = raw_data_path / ('lh'+files_2_read['DKT']['ct']);        rh_DKT_ct_file = raw_data_path /  ('rh'+files_2_read['DKT']['ct']);\n",
    "    lh_DKT_vol_file = raw_data_path / ('lh'+files_2_read['DKT']['volume']);       rh_DKT_vol_file = raw_data_path / ('rh'+files_2_read['DKT']['volume']);\n",
    "\n",
    "    ## drop_list\n",
    "    aseg_drop = [\"EstimatedTotalIntraCranialVol\"]; \n",
    "    wm_drop = [\"MaskVol\", \"EstimatedTotalIntraCranialVol\", \"CerebralWhiteMatterVol\", \"rhCerebralWhiteMatterVol\", \"lhCerebralWhiteMatterVol\"];\n",
    "    parc_drop = [\"BrainSegVolNotVent\", \"eTIV\"]; \n",
    "    \n",
    "    sub_list.loc[:, 'session'] = len(sub_list)*[ses_list[i_ses]]\n",
    "    \n",
    "    # read files\n",
    "    subcortical_tab = pd.read_csv(subcortical_file, sep='\\t', header=0, index_col=0); \n",
    "    subcortical_tab['eTIV']=subcortical_tab['EstimatedTotalIntraCranialVol']\n",
    "    subcortical_tab.drop(aseg_drop, axis=1, inplace=True);\n",
    "    # site\n",
    "    res = sub_list.join(subcortical_tab, how='left');\n",
    "    wm_tab = pd.read_csv(wm_file, sep='\\t', header=0, index_col=0); wm_tab.drop(wm_drop, axis=1, inplace=True);\n",
    "    res1   = res.join(wm_tab, how='left');\n",
    "\n",
    "    # read Des/DKT parcelation data\n",
    "    lh_Des_ct_tab  = pd.read_csv(lh_Des_ct_file,  sep='\\t', header=0, index_col=0);       lh_Des_ct_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "    rh_Des_ct_tab  = pd.read_csv(rh_Des_ct_file,  sep='\\t', header=0, index_col=0);       rh_Des_ct_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "    lh_Des_vol_tab = pd.read_csv(lh_Des_vol_file, sep='\\t', header=0, index_col=0);       lh_Des_vol_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "    rh_Des_vol_tab = pd.read_csv(rh_Des_vol_file, sep='\\t', header=0, index_col=0);       rh_Des_vol_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "    lh_Des_area_tab = pd.read_csv(lh_Des_area_file, sep='\\t', header=0, index_col=0);     lh_Des_area_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "    rh_Des_area_tab = pd.read_csv(rh_Des_area_file, sep='\\t', header=0, index_col=0);     rh_Des_area_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "\n",
    "    # DKT atlas\n",
    "    lh_DKT_ct_tab  = pd.read_csv(lh_DKT_ct_file,  sep='\\t', header=0, index_col=0);       lh_DKT_ct_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "    rh_DKT_ct_tab  = pd.read_csv(rh_DKT_ct_file,  sep='\\t', header=0, index_col=0);       rh_DKT_ct_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "    lh_DKT_vol_tab = pd.read_csv(lh_DKT_vol_file, sep='\\t', header=0, index_col=0);       lh_DKT_vol_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "    rh_DKT_vol_tab = pd.read_csv(rh_DKT_vol_file, sep='\\t', header=0, index_col=0);       rh_DKT_vol_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "    lh_DKT_area_tab = pd.read_csv(lh_DKT_area_file, sep='\\t', header=0, index_col=0);     lh_DKT_area_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "    rh_DKT_area_tab = pd.read_csv(rh_DKT_area_file, sep='\\t', header=0, index_col=0);     rh_DKT_area_tab.drop(parc_drop, axis=1, inplace=True);\n",
    "\n",
    "    # merge Des/DKT parcelation data\n",
    "    seg_Des_tab=       res1.join(lh_Des_ct_tab, how='left');  seg_Des_tab=seg_Des_tab.join(rh_Des_ct_tab, how='left'); \n",
    "    seg_Des_tab=seg_Des_tab.join(lh_Des_vol_tab,how='left');  seg_Des_tab=seg_Des_tab.join(rh_Des_vol_tab,how='left'); \n",
    "    seg_Des_tab=seg_Des_tab.join(lh_Des_area_tab,how='left'); seg_Des_tab=seg_Des_tab.join(rh_Des_area_tab,how='left');\n",
    "    \n",
    "    seg_DKT_tab=res1.join(lh_DKT_ct_tab, how='left');         seg_DKT_tab=seg_DKT_tab.join(rh_DKT_ct_tab, how='left'); \n",
    "    seg_DKT_tab=seg_DKT_tab.join(lh_DKT_vol_tab,how='left');  seg_DKT_tab=seg_DKT_tab.join(rh_DKT_vol_tab,how='left'); \n",
    "    seg_DKT_tab=seg_DKT_tab.join(lh_DKT_area_tab,how='left'); seg_DKT_tab=seg_DKT_tab.join(rh_DKT_area_tab,how='left'); \n",
    "    # return data\n",
    "    group_data[ses_list[i_ses]]={'Des': seg_Des_tab, 'DKT':seg_DKT_tab}\n",
    "\n",
    "all_data = {'Des': pd.concat([group_data['1']['Des'], group_data['2']['Des'], group_data['3']['Des']]), 'DKT': pd.concat([group_data['1']['DKT'], group_data['2']['DKT'], group_data['3']['DKT']])}\n",
    "for k, v in all_data.items():\n",
    "    v.index   = [x.replace('-','_') for x in v.index]\n",
    "    v.columns = [x.replace('-','_') for x in v.columns]\n",
    "\n",
    "hippo_Des_list = ['session', 'Left_Hippocampus', 'Right_Hippocampus', 'wm_lh_parahippocampal', 'wm_rh_parahippocampal']\n",
    "hippo_DKT_list = ['session', 'Left_Hippocampus', 'Right_Hippocampus', 'wm_lh_parahippocampal', 'wm_rh_parahippocampal', 'lh_parahippocampal_volume', 'rh_parahippocampal_volume', 'lh_parahippocampal_thickness', 'rh_parahippocampal_thickness', 'lh_parahippocampal_area', 'rh_parahippocampal_area']\n",
    "for x in ses_list:\n",
    "    print(x , len(group_data[x]['Des']))\n",
    "if save_file ==1:\n",
    "    all_data['Des'].to_csv(des_sv_file)\n",
    "    all_data['DKT'].to_csv(dkt_sv_file)\n",
    "    all_data['Des'].loc[:,hippo_Des_list].to_csv(des_hippo_sv_file)\n",
    "    all_data['DKT'].loc[:,hippo_DKT_list].to_csv(dkt_hippo_sv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336499a3",
   "metadata": {},
   "source": [
    "Functional and anatomical knowledge of the ROIs selected:\n",
    "\n",
    "    1. Parahippocampal gyrus:\n",
    " https://en.wikipedia.org/wiki/Parahippocampal_gyrus#:~:text=The%20parahippocampal%20gyrus%20(or%20hippocampal,some%20cases%20of%20hippocampal%20sclerosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e56aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple visualization of hippocampus measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82964c19-8a60-4a6d-acdc-078179e42219",
   "metadata": {},
   "source": [
    "## Generate subject list for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffe9a03-7ab6-45eb-ae23-bc2cffd5fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate files for QA\n",
    "# output QA subject list \n",
    "mdd_qa_file   = main_dir / \"scripts\" / \"QA\" / 'runningMDD_qa_list.csv'  # Information from download database.\n",
    "data_df.to_csv(mdd_qa_file, columns=[], header=False)\n",
    "#generate the subject list for freesurfer results collection\n",
    "print(\"Subject list space seperated: \")\n",
    "print(' '.join((data_df.index)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
